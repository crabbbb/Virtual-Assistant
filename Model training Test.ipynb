{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5797873",
   "metadata": {},
   "source": [
    "### Resource use \n",
    "\n",
    "- [Reference Video](https://www.youtube.com/watch?v=u2diEa4VT4M&t=83s&ab_channel=AllAboutAI)\n",
    "- [Run Llama 2 Locally with Python](https://swharden.com/blog/2023-07-29-ai-chat-locally-with-python/)\n",
    "- [llama-cpp-python](https://pypi.org/project/llama-cpp-python/)\n",
    "    - Tutorial \n",
    "        - https://www.datacamp.com/tutorial/llama-cpp-tutorial\n",
    "- [Mistral-7B-Instruct-v0.1-GGUF](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f0027",
   "metadata": {},
   "source": [
    "## Model Installing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-cpp-python\n",
    "\n",
    "# version check \n",
    "# pip show llama-cpp-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597cce6",
   "metadata": {},
   "source": [
    "### Test Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709195d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the large language model file\n",
    "# from llama_cpp import Llama\n",
    "# LLM = Llama(model_path=\"model/mistral-7b-instruct-v0.1.Q5_K_M.gguf\")\n",
    "\n",
    "# # create a text prompt\n",
    "# prompt = \"Q: What are the names of the days of the week?\"\n",
    "\n",
    "# # generate a response (takes several seconds)\n",
    "# output = LLM(prompt)\n",
    "\n",
    "# # display the response\n",
    "# print(prompt)\n",
    "# print(output[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82b0ee",
   "metadata": {},
   "source": [
    "## Train Model - Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db34e62",
   "metadata": {},
   "source": [
    "[ShortCut Key](https://digitalhumanities.hkust.edu.hk/tutorials/jupyter-notebook-tips-and-shortcuts/)\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Reference \n",
    "- [Guide to Fine-Tuning LLMs](https://www.datacamp.com/tutorial/fine-tuning-large-language-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339256b",
   "metadata": {},
   "source": [
    "### Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install trl \n",
    "# pip install peft\n",
    "# pip install torch\n",
    "# pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3920c488",
   "metadata": {},
   "source": [
    "Error facing when installing trl, peft & torch\n",
    "\n",
    "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus\n",
    "    we cannot accurately determine which files belong to it which would lead to\n",
    "    only a partial uninstall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0a18a",
   "metadata": {},
   "source": [
    "[Pandas Official DataFrame Tutorial](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)\n",
    "<br><br>\n",
    "[W3School Pandas DataFrame](https://www.w3schools.com/python/pandas/pandas_dataframes.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7602b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49495ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n",
    "\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data in table form\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e75c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly convert to pandas format without create library  \n",
    "pandas_format = dataset[\"train\"].to_pandas()\n",
    "display(pandas_format.size) # check size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4caf13d",
   "metadata": {},
   "source": [
    "<code>display()</code> can directly display in table form ( more better ) <br>\n",
    "- <code>DataFrame.head()</code> first 5 row <br>\n",
    "- <code>DataFrame.tail()</code> last 5 row <br>\n",
    "\n",
    "<code>print()</code> will only display without formating <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efefeb7d",
   "metadata": {},
   "source": [
    "# Speech To Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package installation\n",
    "# pip install SpeechRecognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as speech\n",
    "\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff878ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable - capture speech\n",
    "recognizer = speech.Recognizer()\n",
    "\n",
    "# global variable - conversation [end user question][machine response]\n",
    "convo = []\n",
    "\n",
    "# global variable - common sentences\n",
    "NOT_UNDERSTAND = \"Sorry, I didn't understand that. I only can understanding english\"\n",
    "ERROR = \"Unexpected Error Occurs. Message to Developer > \"\n",
    "NOT_CLEAR = \"I'm sorry I didn't catch what you said. Could you repeat it, please\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to store conversation \n",
    "def inRange(index):\n",
    "    return index >= 0 and index < len(convo) # true of false \n",
    "\n",
    "# setter \n",
    "def setQuestion(ques): \n",
    "    convo.append([str(ques)])\n",
    "    \n",
    "# function to store conversation \n",
    "def setResponse(res):\n",
    "    convo[len(convo) - 1].append(str(res))\n",
    "\n",
    "## ( int - index , string )\n",
    "def setResponseWithNum(index, res):\n",
    "    if inRange(index):\n",
    "        convo[index].append(str(res))\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "## ( int - index , string )\n",
    "def setResponseWithNum(index, res):\n",
    "    if inRange(index):\n",
    "        convo[index].append(str(res))\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "# getter \n",
    "def getLatestQuestion():\n",
    "    return convo[len(convo) - 1][0]    \n",
    "\n",
    "def getLatestResponse():\n",
    "    return convo[len(convo) - 1][1]\n",
    "\n",
    "def getQuestionWithNum(index):\n",
    "    if inRange(index):\n",
    "        return convo[index][0]\n",
    "    # out of index\n",
    "    return None \n",
    "\n",
    "def getResponseWithNum(index):\n",
    "    if inRange(index):\n",
    "        return convo[index][1]\n",
    "    # out of index\n",
    "    return None \n",
    "\n",
    "# Example of using\n",
    "# setQuestion(\"hello\")\n",
    "# setResponse(\"Hello how can i help u\")\n",
    "# [['hello', 'Hello how can i help u']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to capture speech as input \n",
    "def capature_speech():\n",
    "    try:\n",
    "        with speech.Microphone() as mic:\n",
    "            print(\"listening\")\n",
    "            audio = recognizer.listen(mic, timeout=3)\n",
    "        return audio\n",
    "    except speech.WaitTimeoutError as e:\n",
    "        # within the time limit doesnot have any sound \n",
    "        raise speech.WaitTimeoutError(e)\n",
    "\n",
    "# ******** Error to be handle ******** \n",
    "# WaitTimeoutError: listening timed out while waiting for phrase to start\n",
    "# Define : no talking when listening "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c682e8a",
   "metadata": {},
   "source": [
    "## ⭐Error Catching List \n",
    "\n",
    "- [ x ] speech.WaitTimeoutError\n",
    "- [ x ] speech.RequestError\n",
    "- [ x ] speech.UnknownValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55345ae1",
   "metadata": {},
   "source": [
    "https://rollbar.com/blog/throwing-exceptions-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting speech to text\n",
    "def convert_speechToText(audio):\n",
    "    text = \"\"\n",
    "    try: \n",
    "        # converting \n",
    "        text = recognizer.recognize_google(audio)\n",
    "        \n",
    "        return text\n",
    "    except speech.UnknownValueError as e:\n",
    "        # unknown language / no speech / sound  \n",
    "        raise speech.UnknownValueError(e)\n",
    "    except speech.RequestError as e:\n",
    "        raise speech.RequestError(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b7054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the large language model file\n",
    "def load_model():\n",
    "    return Llama(model_path=\"model/mistral-7b-instruct-v0.1.Q5_K_M.gguf\")\n",
    "\n",
    "LLM = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only when the audio convert to text successful \n",
    "def generate_output(input):\n",
    "    # generate a response (takes several seconds)\n",
    "    output = LLM(input)\n",
    "    text = output[\"choices\"][0][\"text\"].strip()\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_inputVoice(): \n",
    "    text = \"\"\n",
    "    \n",
    "    try:\n",
    "        # create a text prompt\n",
    "        audio = capature_speech()\n",
    "        text = convert_speechToText(audio)\n",
    "\n",
    "        # store question \n",
    "        setQuestion(text)    \n",
    "        \n",
    "        return True\n",
    "\n",
    "    except speech.WaitTimeoutError as e:\n",
    "        # not sound when listening cause timeout\n",
    "        setQuestion(\"Problem occurs when receiving input\")\n",
    "        setResponse(NOT_CLEAR)\n",
    "    except speech.UnknownValueError as e:\n",
    "        # cause when convert problem\n",
    "        setQuestion(\"Problem occurs when receiving input\")\n",
    "        setResponse(NOT_UNDERSTAND)\n",
    "    except speech.RequestError as e:\n",
    "        # IDK\n",
    "        setQuestion(\"Problem occurs when receiving input\")\n",
    "        setResponse(ERROR + format(e))\n",
    "    except Exception as e: \n",
    "        setQuestion(\"Problem occurs when receiving input\")\n",
    "        setResponse(format(e))\n",
    "    return False # input get unsuccessful - no continuos processing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd21310",
   "metadata": {},
   "source": [
    "# Business suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86fff6",
   "metadata": {},
   "source": [
    "- [The best post that I have ever seen](https://stackoverflow.com/questions/65199011/is-there-a-way-to-check-similarity-between-two-full-sentences-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b03716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup\n",
    "# pip install spacy\n",
    "\n",
    "# python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ba900",
   "metadata": {},
   "source": [
    "## Check Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable - check similarity \n",
    "Res_keyword = [\"restaurant\", \"suggest\", \"top restaurant\", \"few\", \"some\", \"lauch\"]\n",
    "Res_sentence = [\"can you suggest a few restaurant\", \"which are the top restaurant in\", \"please help me to found a restaurant in Malaysia, that have high rating\"]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1afe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def get_similarity(sent1, sent2):\n",
    "    doc1 = nlp(sent1)\n",
    "    doc2 = nlp(sent2)\n",
    "    print(doc1.similarity(doc2))\n",
    "    return doc1.similarity(doc2)\n",
    "\n",
    "def isSimilar(sent1, sent2):\n",
    "    if get_similarity(sent1.lower(), sent2.lower()) > 0.70:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "# print(get_similarity('can you suggest a few restaurant in', 'please help me to found a restaurant in Malaysia, that have high rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule based for Hi and Hello\n",
    "rule = [[\"Hello\", \"Hello ~ how can I help you\"], \n",
    "       [\"Who you are\", \"I am a Large Language Model - LLM create by Mistral 7b\"]]\n",
    "\n",
    "def checkRegard(input):\n",
    "    if isSimilar(rule[0][0], input):\n",
    "        setResponse(rule[0][1])\n",
    "        return True\n",
    "    elif isSimilar(rule[1][0], input):\n",
    "        setResponse(rule[1][1])\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416fcc9",
   "metadata": {},
   "source": [
    "## Convert convo into PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ironpdf\n",
    "\n",
    "# pip show ironpdf\n",
    "\n",
    "# !python -m pip uninstall ironpdf --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58389d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f02d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import datetime as date\n",
    "\n",
    "# save FPDF() class into a \n",
    "# variable pdf\n",
    "pdf = FPDF()\n",
    " \n",
    "# Add a page\n",
    "pdf.add_page()\n",
    "\n",
    "# set style and size of font \n",
    "# that you want in the pdf\n",
    "pdf.set_font(\"Arial\", size = 15)\n",
    "\n",
    "for qna in convo:\n",
    "    pdf.cell(200, 10, txt = \"You : \" + qna[0][0], \n",
    "         ln = 1, align = 'L')\n",
    "    pdf.cell(200, 10, txt = \"Robot : \" + qna[0][1], \n",
    "         ln = 1, align = 'L')\n",
    "\n",
    "# save the pdf with name .pdf\n",
    "date = date.datetime.now()\n",
    "pdf.output(f\"convo_{date.year}{date.month}{date.day}{date.hour}{date.second}{date.microsecond}.pdf\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05414486",
   "metadata": {},
   "source": [
    "# Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4392364",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyttsx3 # sound output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870ab1d",
   "metadata": {},
   "source": [
    "https://hackernoon.com/an-essential-python-text-to-speech-tutorial-using-the-pyttsx3-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815dab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-to-speech setting \n",
    "import pyttsx3 as tts\n",
    "\n",
    "def machineInitSetting():\n",
    "    volume = machine.getProperty('volume')\n",
    "    machine.setProperty('volume', volume+1.00)\n",
    "    voices = machine.getProperty('voices')\n",
    "    machine.setProperty('voice', voices[0].id)\n",
    "\n",
    "def generate_sound(res):\n",
    "    machine.say(res)\n",
    "    machine.runAndWait()\n",
    "\n",
    "machine = tts.init()\n",
    "machineInitSetting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30cb552",
   "metadata": {},
   "source": [
    "## OpenVoice Problem\n",
    "- cannot install torch\n",
    "- https://www.youtube.com/watch?v=1ec-jOlxt_E&ab_channel=WingnutLabs\n",
    "- https://www.youtube.com/watch?v=dLNN36hU06M&ab_channel=MG\n",
    "- https://blog.unrealspeech.com/openvoice-completed-guide/\n",
    "- https://github.com/myshell-ai/OpenVoice/blob/main/demo_part1.ipynb\n",
    "- https://github.com/myshell-ai/OpenVoice/issues/98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b479f2fc",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0da018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf4a5d",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def load_knowledge_base(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as file:\n",
    "        data: dict = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_knowledge_base(file_path: str, data: dict):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "\n",
    "def find_best_match(user_question: str, questions: list[str]) -> str | None:\n",
    "    # 60 % similiar res\n",
    "    matches: list = get_close_matches(user_question, questions, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "\n",
    "\n",
    "def get_answer_for_question(question: str, knowledge_base: dict) -> str | None:\n",
    "    for q in knowledge_base[\"questions\"]:\n",
    "        if q[\"question\"] == question:\n",
    "            return q[\"answer\"]\n",
    "\n",
    "def chat_bot():\n",
    "    knowledge_base: dict = load_knowledge_base('knowledge_base.json')\n",
    "        \n",
    "    while True:\n",
    "        user_input: str = input('You : ')\n",
    "            \n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        # search best match inside json file \n",
    "        best_match: str | None = find_best_match(user_input, [q['question'] for q in knowledge_base['questions']])\n",
    "        \n",
    "        if best_match:\n",
    "            answer: str = get_answer_for_question(best_match, knowledge_base)\n",
    "            print(f'Bot : {answer}')\n",
    "            generate_sound(answer)\n",
    "        else:\n",
    "            # let machine to make a response \n",
    "            answer = generate_output(user_input)\n",
    "            print(f'Bot : {answer}')\n",
    "            generate_sound(answer)\n",
    "#             print('Bot : I dont know the answer')\n",
    "#             new_answer: str = input('Type the answer or \"skip\" to skip: ')\n",
    "                \n",
    "#             if new_answer.lower() != 'skip':\n",
    "#                 knowledge_base['questions'].append({\"question\": user_input, \"answer\": new_answer})\n",
    "#                 save_knowledge_base('knowledge_base.json', knowledge_base)\n",
    "#                 print('Bot : Thank you! I learned a new response!')\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    chat_bot()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3e497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f47f96",
   "metadata": {},
   "source": [
    "# Algorithm global setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers==4.32.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama_cpp_python==0.2.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6409737",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c1359",
   "metadata": {},
   "source": [
    "- if <code>pip install torch</code> is not useful, still got problem when running torch can use the code below<br>\n",
    "    <code>conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SpeechRecognition==3.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyttsx3==2.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7814080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyAudio==0.2.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fpdf==1.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3787a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy==1.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ff564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim==3.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa48b2",
   "metadata": {},
   "source": [
    "- if cannot run please go to \"..\\anaconda3\\Lib\\site-packages\\gensim\\corpora\\dictionary.py\" change <br>\n",
    "\n",
    "    <code>from collections import Mapping, defaultdict</code>\n",
    "    <br>\n",
    "    change to\n",
    "    <br>\n",
    "    <code>from collections.abc import Mapping</code> and\n",
    "    <br>\n",
    "    <code>from collections import defaultdict</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tk==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pillow==10.3.0 # this one not sure have install or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f65740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Model path\n",
    "path_gpt2 = 'gpt2'\n",
    "path_mistral = 'model/mistral-7b-instruct-v0.1.Q5_K_M.gguf'\n",
    "path_dialo = 'microsoft/DialoGPT-medium'\n",
    "\n",
    "GPT = 'GPT-2'\n",
    "MISTRAL = 'Mistral 7B'\n",
    "DIALO = 'DialoGPT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a684d",
   "metadata": {},
   "source": [
    "## Algorithm 1 - GPT2\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/model_doc/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d6dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ques = \"which business have serve alcohol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98674891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def getGPT(ques:str):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "    prompt = \"GPT2 is a model developed by OpenAI.\"\n",
    "\n",
    "    input_ids = tokenizer(ques, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    gen_tokens = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        max_length=100,\n",
    "    )\n",
    "    gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "    return gen_text\n",
    "\n",
    "# print(getGPT(ques))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4de34",
   "metadata": {},
   "source": [
    "## Algorithm 2 - Mistral 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a6031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the large language model file\n",
    "from llama_cpp import Llama\n",
    "\n",
    "def get_res_from_mistral(ques: str):\n",
    "    LLM = Llama(model_path=path_mistral)\n",
    "    \n",
    "    # generate a response (takes several seconds)\n",
    "    output = LLM(ques)\n",
    "    \n",
    "    return output[\"choices\"][0][\"text\"]\n",
    "\n",
    "# display the response\n",
    "# print(ques)\n",
    "# print(output[\"choices\"][0][\"text\"])\n",
    "\n",
    "# print(ques)\n",
    "# print('Mistral 7b > ' + get_res_from_mistral(ques))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe3e440",
   "metadata": {},
   "source": [
    "## Algorithm 3 - DialoGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a04096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def get_res_from_dialo(ques: str):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path_dialo)\n",
    "    model = AutoModelForCausalLM.from_pretrained(path_dialo)\n",
    "\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(ques + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    bot_input_ids = new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    # pretty print last ouput tokens from bot\n",
    "    return format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True))\n",
    "\n",
    "# print(chat_history_ids)\n",
    "# print(chat_history_ids[:, bot_input_ids.shape[-1]:][0])\n",
    "# print(bot_input_ids.shape[-1])\n",
    "# print(bot_input_ids.shape)\n",
    "\n",
    "# print(get_res_from_dialo(ques))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfa01e",
   "metadata": {},
   "source": [
    "# Speech To Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6ec6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb00aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable - capture speech\n",
    "recognizer = speech.Recognizer()\n",
    "\n",
    "# global variable - conversation [end user question][machine response]\n",
    "convo = []\n",
    "\n",
    "# global variable - common sentences\n",
    "NOT_UNDERSTAND = \"Sorry, I didn't understand that. I only can understanding english\"\n",
    "ERROR = \"Unexpected Error Occurs. Message to Developer > \"\n",
    "NOT_CLEAR = \"I'm sorry I didn't catch what you said. Could you repeat it, please\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0569db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to store conversation \n",
    "def inRange(index):\n",
    "    return index >= 0 and index < len(convo) # true of false \n",
    "\n",
    "# setter \n",
    "def setQuestion(ques): \n",
    "    convo.append([str(ques)])\n",
    "    \n",
    "# function to store conversation \n",
    "def setResponse(res):\n",
    "    convo[len(convo) - 1].append(str(res))\n",
    "\n",
    "## ( int - index , string )\n",
    "def setResponseWithNum(index, res):\n",
    "    if inRange(index):\n",
    "        convo[index].append(str(res))\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "## ( int - index , string )\n",
    "def setResponseWithNum(index, res):\n",
    "    if inRange(index):\n",
    "        convo[index].append(str(res))\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "# getter \n",
    "def getLatestQuestion():\n",
    "    return convo[len(convo) - 1][0]    \n",
    "\n",
    "def getLatestResponse():\n",
    "    return convo[len(convo) - 1][1]\n",
    "\n",
    "def getQuestionWithNum(index):\n",
    "    if inRange(index):\n",
    "        return convo[index][0]\n",
    "    # out of index\n",
    "    return None \n",
    "\n",
    "def getResponseWithNum(index):\n",
    "    if inRange(index):\n",
    "        return convo[index][1]\n",
    "    # out of index\n",
    "    return None \n",
    "\n",
    "# Example of using\n",
    "# setQuestion(\"hello\")\n",
    "# setResponse(\"Hello how can i help u\")\n",
    "# [['hello', 'Hello how can i help u']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b6966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to capture speech as input \n",
    "def capature_speech():\n",
    "    try:\n",
    "        with speech.Microphone() as mic:\n",
    "            print(\"listening\")\n",
    "            audio = recognizer.listen(mic, timeout=3)\n",
    "        return audio\n",
    "    except speech.WaitTimeoutError as e:\n",
    "        # within the time limit doesnot have any sound \n",
    "        raise speech.WaitTimeoutError(e)\n",
    "\n",
    "# ******** Error to be handle ******** \n",
    "# WaitTimeoutError: listening timed out while waiting for phrase to start\n",
    "# Define : no talking when listening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36fe17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting speech to text\n",
    "def convert_speechToText(audio):\n",
    "    text = \"\"\n",
    "    try: \n",
    "        # converting \n",
    "        text = recognizer.recognize_google(audio)\n",
    "        \n",
    "        return text\n",
    "    except speech.UnknownValueError as e:\n",
    "        # unknown language / no speech / sound  \n",
    "        raise speech.UnknownValueError(e)\n",
    "    except speech.RequestError as e:\n",
    "        raise speech.RequestError(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd20901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only when the audio convert to text successful \n",
    "def generate_output(input):\n",
    "    # generate a response (takes several seconds)\n",
    "    output = LLM(input)\n",
    "    text = output[\"choices\"][0][\"text\"].strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3b6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_inputVoice(): \n",
    "    text = \"\"\n",
    "    \n",
    "    try:\n",
    "        # create a text prompt\n",
    "        audio = capature_speech()\n",
    "        text = convert_speechToText(audio)\n",
    "\n",
    "        # store question \n",
    "        setQuestion(text)    \n",
    "        \n",
    "        return True\n",
    "\n",
    "    except speech.WaitTimeoutError as e:\n",
    "        # not sound when listening cause timeout\n",
    "        setQuestion(\"Problem occurs when receiving input\")\n",
    "        setResponse(NOT_CLEAR)\n",
    "    except speech.UnknownValueError as e:\n",
    "        # cause when convert problem\n",
    "        setQuestion(\"Problem occurs when receiving input\")\n",
    "        setResponse(NOT_UNDERSTAND)\n",
    "    except speech.RequestError as e:\n",
    "        # IDK\n",
    "        setQuestion(\"Problem occurs when receiving input\")\n",
    "        setResponse(ERROR + format(e))\n",
    "    except Exception as e: \n",
    "        setQuestion(\"Problem occurs when receiving input\")\n",
    "        setResponse(format(e))\n",
    "    return False # input get unsuccessful - no continuos processing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e9443",
   "metadata": {},
   "source": [
    "# Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2105861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-to-speech setting \n",
    "import pyttsx3 as tts\n",
    "\n",
    "def machineInitSetting():\n",
    "    volume = machine.getProperty('volume')\n",
    "    machine.setProperty('volume', volume+1.00)\n",
    "    voices = machine.getProperty('voices')\n",
    "    machine.setProperty('voice', voices[0].id)\n",
    "\n",
    "def generate_sound(res):\n",
    "    machine.say(res)\n",
    "    machine.runAndWait()\n",
    "\n",
    "machine = tts.init()\n",
    "machineInitSetting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8ffd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_response(ques, algorithm):\n",
    "    res = \"\"\n",
    "    if algorithm != None:\n",
    "        # means got things to do \n",
    "        if algorithm == MISTRAL:\n",
    "            # let mistral generate response\n",
    "            res = get_res_from_mistral(ques)\n",
    "        elif algorithm == GPT:\n",
    "            # let GPT2 generate response\n",
    "            res = getGPT(ques)\n",
    "        else:\n",
    "            # let DialoGPT generate response\n",
    "            res = get_res_from_dialo(ques)\n",
    "        \n",
    "        process_response(res)\n",
    "        return res\n",
    "\n",
    "def process_response(res):\n",
    "    print(\"process response\")\n",
    "    setResponse(res)\n",
    "    generate_sound(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a20a2",
   "metadata": {},
   "source": [
    "# Check Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00cf346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def get_similarity(sent1, sent2):\n",
    "    doc1 = nlp(sent1)\n",
    "    doc2 = nlp(sent2)\n",
    "    print(doc1.similarity(doc2))\n",
    "    return doc1.similarity(doc2)\n",
    "\n",
    "def isSimilar(sent1, sent2):\n",
    "    if get_similarity(sent1.lower(), sent2.lower()) > 0.70:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# print(get_similarity('can you suggest a few restaurant in', 'please help me to found a restaurant in Malaysia, that have high rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "462565cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule based for Hi and Hello\n",
    "\n",
    "def checkRegard(input):\n",
    "    if isSimilar(rule[0][0], input):\n",
    "        setResponse(rule[0][1])\n",
    "        return True\n",
    "    elif isSimilar(rule[1][0], input):\n",
    "        setResponse(rule[1][1])\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715082a",
   "metadata": {},
   "source": [
    "# Convert convo into PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d60f308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import datetime as date\n",
    "\n",
    "def exportConvoToPDF(date: date):\n",
    "    print(convo)\n",
    "    # save FPDF() class into a \n",
    "    # variable pdf\n",
    "    pdf = FPDF()\n",
    "\n",
    "    # Add a page\n",
    "    pdf.add_page()\n",
    "\n",
    "    # set style and size of font \n",
    "    # that you want in the pdf\n",
    "    pdf.set_font(\"Arial\", size = 15)\n",
    "\n",
    "    for qna in convo:\n",
    "        pdf.cell(200, 10, txt = \"You : \" + qna[0], \n",
    "             ln = 1, align = 'L')\n",
    "        pdf.cell(200, 10, txt = \"Robot : \" + qna[1], \n",
    "             ln = 1, align = 'L')\n",
    "\n",
    "    # save the pdf with name .pdf\n",
    "    # date = date.datetime.now()\n",
    "    pdf.output(f\"convo_{date.year}{date.month}{date.day}{date.hour}{date.second}{date.microsecond}.pdf\") \n",
    "\n",
    "# exportConvoToPDF(date.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c6172",
   "metadata": {},
   "source": [
    "# Searching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0243247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "# open with chorme \n",
    "chrome_path = \"C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Google Chrome.lnk\"\n",
    "CHROME = \"chrome\"\n",
    "# open with microsoft edges\n",
    "microsoft_path = \"C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Microsoft Edge.lnk\"\n",
    "MICROSOFT = \"microsoft edges\"\n",
    "\n",
    "# default setting \n",
    "webbrowser.register( CHROME, None, webbrowser.BackgroundBrowser(chrome_path))\n",
    "\n",
    "search_k = ['search', 'open']\n",
    "\n",
    "# register the default\n",
    "def registerDefaultSearch(browser: str):\n",
    "    if browser == CHROME:\n",
    "        webbrowser.register( CHROME, None, webbrowser.BackgroundBrowser(chrome_path))\n",
    "    else:\n",
    "        webbrowser.register( MICROSOFT, None, webbrowser.BackgroundBrowser(microsoft_path))\n",
    "\n",
    "# removeStart and removeEnd will not be include into the query\n",
    "def getQuery(query: str, removeStart: str, removeEnd: str):\n",
    "    # get the content before 'search' | 'go to' & after 'by' | 'at' | 'on'\n",
    "    if removeStart != None:\n",
    "        indexStart = text.index(removeStart) + len(removeStart) # include\n",
    "        query = query[indexStart:]\n",
    "    if removeEnd != None:\n",
    "        indexEnd = text.index(removeEnd) # exclude\n",
    "        query = query[:indexEnd]\n",
    "    return query\n",
    "\n",
    "def search(browser: str, query: str):\n",
    "    webbrowser.get(browser).open_new(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "041962f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy==1.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5453897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# to extract what user want & get more precise result\n",
    "from gensim.summarization import keywords\n",
    "# if cannot run please go to \"..\\anaconda3\\Lib\\site-packages\\gensim\\corpora\\dictionary.py\" change \n",
    "'''\n",
    "from collections import Mapping, defaultdict\n",
    "<br>\n",
    "change to\n",
    "<br>\n",
    "from collections.abc import Mapping\n",
    "from collections import defaultdict\n",
    "'''\n",
    "\n",
    "def retreive_keyword(ques):\n",
    "    text_en = (ques)\n",
    "    key = keywords(text_en, words = 2, scores = True, lemmatize = True)\n",
    "    return key\n",
    "\n",
    "print(retreive_keyword(\"and the sections\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74b5a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "017fa895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checklistExistInString(sstr: str, Llist: list):\n",
    "    for i in Llist:\n",
    "        if i in sstr:\n",
    "            return True\n",
    "\n",
    "def isSearch(ques: str):\n",
    "    resultList = retreive_keyword(str)\n",
    "    if not resultList and resultList in search_k: # action match\n",
    "        return True\n",
    "    elif checklistExistInString(ques, search_k):\n",
    "        # prevent unuseful keyword retrieve\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0118e3",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "233d0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_section = ['terminate', 'end', 'quit', 'stop', 'bye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "687023fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrome :\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from difflib import get_close_matches\n",
    "\n",
    "knowledge_path = \"knowledge_base.json\"\n",
    "\n",
    "def load_knowledge_base(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as file:\n",
    "        data: dict = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_knowledge_base(file_path: str, data: dict):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "def find_best_match(user_question: str, questions: list[str]) -> str | None:\n",
    "    # 60 % similiar res\n",
    "    matches: list = get_close_matches(user_question, questions, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "def get_answer_for_question(question: str, knowledge_base: dict) -> str | None:\n",
    "    for q in knowledge_base[\"questions\"]:\n",
    "        if q[\"question\"] == question:\n",
    "            return q[\"answer\"]\n",
    "\n",
    "def getDefaultBrowser(knowledge_base: dict):\n",
    "    return knowledge_base[\"settings\"][\"defaultBrowser\"]\n",
    "\n",
    "def updateCurrentServebot(file_path: str, data: dict):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "        \n",
    "def getCurrentServebot(knowledge_base: dict):\n",
    "    return knowledge_base[\"settings\"][\"currentServebot\"]\n",
    "\n",
    "def chat_bot():\n",
    "    # open the file\n",
    "    knowledge_base: dict = load_knowledge_base(knowledge_path)\n",
    "    \n",
    "    while True:\n",
    "        # if sucessful get input \n",
    "        if receive_inputVoice:\n",
    "            user_input: str = getLatestQuestion()\n",
    "\n",
    "            # user request to end the section \n",
    "            if user_input.lower() in end_section:\n",
    "                break\n",
    "\n",
    "            # search best match inside json file \n",
    "            best_match: str | None = find_best_match(user_input, [q['question'] for q in knowledge_base['questions']])\n",
    "\n",
    "            if best_match:\n",
    "                # found best match - use knowledge based to response\n",
    "                answer: str = get_answer_for_question(best_match, knowledge_base)\n",
    "                ## display at nested screen\n",
    "                print(f'{getCurrentServebot()} : {answer}')\n",
    "                generate_sound(answer)\n",
    "            elif isSearch(user_input):\n",
    "                # request to searching\n",
    "                query = getQuery(user_input)\n",
    "            else:\n",
    "                # let machine to make a response \n",
    "                answer = generate_output(user_input)\n",
    "                print(f'Bot : {answer}')\n",
    "                generate_sound(answer)\n",
    "        else:\n",
    "            print(getLatestResponse())\n",
    "    \n",
    "    return True # end of section\n",
    "\n",
    "\n",
    "\n",
    "# chat finish -- export convo ?\n",
    "# def convoExportAsk():\n",
    "print(f\"{getDefaultBrowser(load_knowledge_base(knowledge_path))} :\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbfe792",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cd5e5e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tk\n",
      "Version: 0.1.0\n",
      "Summary: TensorKit is a deep learning helper between Python and C++.\n",
      "Home-page: https://github.com/atranitell/TensorKit\n",
      "Author: Kai Jin\n",
      "Author-email: atranitell@gmail.com\n",
      "License: Apache 2.0 Licence\n",
      "Location: C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #, install, tkinter\n"
     ]
    }
   ],
   "source": [
    "pip show tk # install tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f017cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Import tkinter library\n",
    "# from tkinter import *\n",
    "# from tkinter import ttk\n",
    "# from PIL import ImageTk, Image\n",
    "# from tkinter import font as tkFont\n",
    "# from tkinter import messagebox, ttk\n",
    "\n",
    "# ### Main Window Setting\n",
    "# mainWin= Tk()\n",
    "\n",
    "# #Set the geometry of tkinter frame\n",
    "# mainWin.geometry(\"750x250\")\n",
    "# mainWin.resizable(False, False)\n",
    "\n",
    "# # ------------------------- combo ------------------------- \n",
    "# selection = MISTRAL # default selection\n",
    "\n",
    "# def selection_changed(event):\n",
    "#     global selection\n",
    "#     selection = combo.get()\n",
    "#     messagebox.showinfo(\n",
    "#         title=\"New Selection\",\n",
    "#         message=f\"Selected option: {selection}\"\n",
    "#     )\n",
    "     \n",
    "# combo = ttk.Combobox(\n",
    "#     state=\"readonly\",\n",
    "#     values=[ MISTRAL, GPT, DIALO ]\n",
    "# )\n",
    "# combo.set(MISTRAL) # set default\n",
    "# combo.place(x=50, y=50)\n",
    "# combo.bind(\"<<ComboboxSelected>>\", selection_changed) # event\n",
    "\n",
    "# # ------------------------- button ------------------------- \n",
    "# micBtn = ttk.Button(mainWin, text=\"Mic\", command=lambda: openNewWindow(selection))\n",
    "# micBtn.place(x=325, y=125)\n",
    "\n",
    "# mainWin.bind('<Return>',lambda event:callback())\n",
    "\n",
    "# mainWin.mainloop()\n",
    "\n",
    "# # ------------------------- function ------------------------- \n",
    "# def openNewWindow(choice):\n",
    "    \n",
    "#     newWindow = Toplevel(mainWin)\n",
    "#     newWindow.title(\"Conversation\")\n",
    "#     newWindow.geometry(\"750x250\")\n",
    "    \n",
    "#     # ------------------------- text ------------------------- \n",
    "#     # Create the chatbot's text area\n",
    "#     text_area = Text(newWindow, bg=\"white\", width=50, height=20)\n",
    "#     text_area.pack()\n",
    "    \n",
    "#     ## looping start and receive input ....\n",
    "#     # open the file\n",
    "#     knowledge_base: dict = load_knowledge_base(knowledge_path)\n",
    "    \n",
    "#     # store model use into json\n",
    "#     updateCurrentServebot(knowledge_path, knowledge_base)\n",
    "#     currentbot = getCurrentServebot(knowledge_base)\n",
    "#     text_area.insert(END, f\"Listening.....\\n\")\n",
    "#     while True:\n",
    "#         # Display the response in the chatbot's text area\n",
    "#         # if sucessful get input \n",
    "#         if receive_inputVoice():\n",
    "#             user_input: str = getLatestQuestion()\n",
    "                \n",
    "#             text_area.insert(END, f\"You : {user_input}\\n\")\n",
    "            \n",
    "#             text_area.insert(END, f\"Processing.....\\n\")\n",
    "            \n",
    "#             # user request to end the section \n",
    "#             if checklistExistInString(user_input.lower(), end_section):\n",
    "#                 # ask for confirm \n",
    "#                 qres = f\"{currentbot}: Confirm to end this section?\"\n",
    "#                 text_area.insert(END, qres + \"\\n\")\n",
    "                \n",
    "#                 # receive input \n",
    "#                 if receive_inputVoice():\n",
    "#                     yn = getLatestQuestion()\n",
    "#                     if \"yes\" in yn.lower() or \"ya\" in yn.lower():\n",
    "#                         # say yes\n",
    "#                         res = \"Okay, bye\"\n",
    "#                         setResponse(res)\n",
    "#                         text_area.insert(END, res + \"\\n\")\n",
    "#                         generate_sound(res)\n",
    "#                         break # exit this section\n",
    "#                     elif \"no\" in yn.lower():\n",
    "#                         # say no\n",
    "#                         res = \"Nice! Let's keep talking\"\n",
    "                    \n",
    "                    \n",
    "#                     text_area.insert(END, res + \"\\n\")\n",
    "#                     process_response(res)\n",
    "                        \n",
    "\n",
    "#             # search best match inside json file \n",
    "#             best_match: str | None = find_best_match(user_input, [q['question'] for q in knowledge_base['questions']])\n",
    "            \n",
    "#             # ----------------------------------------------\n",
    "#             print(user_input)\n",
    "            \n",
    "#             if best_match:\n",
    "#                 # found best match - use knowledge based to response\n",
    "#                 answer: str = get_answer_for_question(best_match, knowledge_base)\n",
    "#                 ## display at nested screen\n",
    "#                 text_area.insert(END, f'{currentbot} : {answer}' + \"\\n\")\n",
    "#             elif isSearch(user_input):\n",
    "#                 # request to searching\n",
    "#                 query = getQuery(user_input)\n",
    "#             else:\n",
    "#                 # let machine to make a response \n",
    "#                 answer = provide_response(user_input, currentbot)\n",
    "#                 text_area.insert(END, f'{currentbot} : {answer}' + \"\\n\")\n",
    "#         else:\n",
    "#             # got problem and come here - NOT_CLEAR, NOT_UNDERSTAND, ERROR....\n",
    "#             print(getLatestResponse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0180e44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# from difflib import get_close_matches\n",
    "\n",
    "# knowledge_path = \"knowledge_base.json\"\n",
    "\n",
    "# def load_knowledge_base(file_path: str) -> dict:\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         data: dict = json.load(file)\n",
    "#     return data\n",
    "\n",
    "# def save_knowledge_base(file_path: str, data: dict):\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         json.dump(data, file, indent=2)\n",
    "\n",
    "# def find_best_match(user_question: str, questions: list[str]) -> str | None:\n",
    "#     # 60 % similiar res\n",
    "#     matches: list = get_close_matches(user_question, questions, n=1, cutoff=0.6)\n",
    "#     return matches[0] if matches else None\n",
    "\n",
    "# def get_answer_for_question(question: str, knowledge_base: dict) -> str | None:\n",
    "#     for q in knowledge_base[\"questions\"]:\n",
    "#         if q[\"question\"] == question:\n",
    "#             return q[\"answer\"]\n",
    "\n",
    "# def getDefaultBrowser(knowledge_base: dict):\n",
    "#     return knowledge_base[\"settings\"][\"defaultBrowser\"]\n",
    "\n",
    "# def updateCurrentServebot(file_path: str, data: dict):\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         json.dump(data, file, indent=2)\n",
    "        \n",
    "# def changeBot(knowledge_base: dict, currentBot: str):\n",
    "#     knowledge_base[\"settings\"][\"currentServebot\"] = currentBot\n",
    "#     updateCurrentServebot(knowledge_path, knowledge_base)\n",
    "        \n",
    "# def getCurrentServebot(knowledge_base: dict):\n",
    "#     return knowledge_base[\"settings\"][\"currentServebot\"]\n",
    "\n",
    "# def chat_bot():\n",
    "#     ## looping start and receive input ....\n",
    "#     # open the file\n",
    "#     knowledge_base: dict = load_knowledge_base(knowledge_path)\n",
    "    \n",
    "#     # store model use into json\n",
    "#     currentbot = getCurrentServebot(knowledge_base)\n",
    "#     changeBot(knowledge_base, currentbot)\n",
    "    \n",
    "#     while True:\n",
    "#         # Display the response in the chatbot's text area\n",
    "#         # if sucessful get input \n",
    "#         if receive_inputVoice():\n",
    "#             user_input: str = getLatestQuestion()\n",
    "            \n",
    "#             print(user_input)\n",
    "            \n",
    "#             # user request to end the section \n",
    "#             if checklistExistInString(user_input.lower(), end_section):\n",
    "#                 # ask for confirm \n",
    "#                 qres = f\"{currentbot}: Confirm to end this section?\"\n",
    "#                 text_area.insert(END, qres + \"\\n\")\n",
    "                \n",
    "#                 # receive input \n",
    "#                 if receive_inputVoice():\n",
    "#                     yn = getLatestQuestion()\n",
    "#                     if \"yes\" in yn.lower() or \"ya\" in yn.lower():\n",
    "#                         # say yes\n",
    "#                         res = \"Okay, bye\"\n",
    "#                         setResponse(res)\n",
    "#                         text_area.insert(END, res + \"\\n\")\n",
    "#                         generate_sound(res)\n",
    "#                         break # exit this section\n",
    "#                     elif \"no\" in yn.lower():\n",
    "#                         # say no\n",
    "#                         res = \"Nice! Let's keep talking\"\n",
    "                    \n",
    "                    \n",
    "#                     print(res)\n",
    "#                     process_response(res)\n",
    "                        \n",
    "\n",
    "#             # search best match inside json file \n",
    "#             best_match: str | None = find_best_match(user_input, [q['question'] for q in knowledge_base['questions']])\n",
    "            \n",
    "#             # ----------------------------------------------\n",
    "#             print(user_input)\n",
    "            \n",
    "#             if best_match:\n",
    "#                 # found best match - use knowledge based to response\n",
    "#                 answer: str = get_answer_for_question(best_match, knowledge_base)\n",
    "#                 ## display at nested screen\n",
    "#                 process_response(answer)\n",
    "#                 print(answer)\n",
    "#                 #text_area.insert(END, f'{currentbot} : {answer}' + \"\\n\")\n",
    "#             else:\n",
    "#                 # let machine to make a response \n",
    "#                 answer = provide_response(user_input, currentbot)\n",
    "#                 process_response(answer)\n",
    "#                 print(answer)\n",
    "#         else:\n",
    "#             # got problem and come here - NOT_CLEAR, NOT_UNDERSTAND, ERROR....\n",
    "#             process_response(getLatestResponse())\n",
    "#             print(getLatestResponse())\n",
    "\n",
    "# chat_bot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8474eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process response\n"
     ]
    }
   ],
   "source": [
    "#Import tkinter library\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import font as tkFont\n",
    "from tkinter import messagebox, ttk\n",
    "import datetime as date\n",
    "\n",
    "def listen():\n",
    "    currentbot = getCurrentServebot(knowledge_base)\n",
    "    text_area.insert(END, f\"Listening.....\\n\")\n",
    "    \n",
    "    if receive_inputVoice():\n",
    "        user_input: str = getLatestQuestion()\n",
    "\n",
    "        text_area.insert(END, f\"You : {user_input}\\n\")\n",
    "\n",
    "        text_area.insert(END, f\"Processing.....\\n\")\n",
    "\n",
    "        # user request to end the section \n",
    "        if checklistExistInString(user_input.lower(), end_section):\n",
    "            \n",
    "            # ask for confirm \n",
    "            qres = f\"{currentbot}: Confirm to end this section?\"\n",
    "            text_area.insert(END, qres + \"\\n\")\n",
    "            process_response(qres)\n",
    "            \n",
    "            # receive input \n",
    "            if receive_inputVoice():\n",
    "                yn = getLatestQuestion()\n",
    "                if \"yes\" in yn.lower() or \"ya\" in yn.lower():\n",
    "                    # say yes\n",
    "                    res = \"Okay, bye\"\n",
    "                    setResponse(res)\n",
    "                    text_area.insert(END, f\"{currentbot} : {res} \\n\")\n",
    "                    generate_sound(res)\n",
    "\n",
    "                elif \"no\" in yn.lower():\n",
    "                    # say no\n",
    "                    res = \"Nice! Let's keep talking\"\n",
    "\n",
    "\n",
    "                text_area.insert(END, f\"{currentbot} : {res} \\n\")\n",
    "                process_response(res)\n",
    "\n",
    "\n",
    "                # search best match inside json file \n",
    "        best_match: str | None = find_best_match(user_input, [q['question'] for q in knowledge_base['questions']])\n",
    "\n",
    "                # ----------------------------------------------\n",
    "        # text_area.insert(END, f\"You : {user_input}\\n\")\n",
    "        # print(user_input)\n",
    "\n",
    "        if best_match:\n",
    "            # found best match - use knowledge based to response\n",
    "            answer: str = get_answer_for_question(best_match, knowledge_base)\n",
    "            \n",
    "            ## display at nested screen\n",
    "            process_response(answer)\n",
    "            text_area.insert(END, f\"{currentbot} : {answer}\\n\")\n",
    "\n",
    "#         elif isSearch(user_input):\n",
    "#             # request to searching\n",
    "#             query = getQuery(user_input)\n",
    "        else:\n",
    "            # let machine to make a response \n",
    "            answer = provide_response(user_input, currentbot)\n",
    "            # process_response(answer)\n",
    "            text_area.insert(END, f\"{currentbot} : {getLatestResponse()}\\n\")\n",
    "    else:\n",
    "        # got problem and come here - NOT_CLEAR, NOT_UNDERSTAND, ERROR....\n",
    "        process_response(getLatestResponse())\n",
    "        text_area.insert(END, f\"You : {getLatestQuestion()}\\n\")\n",
    "        text_area.insert(END, f\"{currentbot} : {getLatestResponse()}\\n\")\n",
    "\n",
    "def exportConvo():\n",
    "    exportConvoToPDF(date.datetime.now())\n",
    "    \n",
    "def updateModelUse(model):\n",
    "    # knowledge_base: dict = load_knowledge_base(knowledge_path)\n",
    "    knowledge_base[\"settings\"][\"currentServebot\"] = model\n",
    "    updateCurrentServebot(knowledge_path, knowledge_base)\n",
    "    \n",
    "\n",
    "### Main Window Setting\n",
    "mainWin= Tk()\n",
    "\n",
    "#Set the geometry of tkinter frame\n",
    "mainWin.geometry(\"750x250\")\n",
    "mainWin.resizable(False, False)\n",
    "\n",
    "# ------------------------- combo ------------------------- \n",
    "selection = MISTRAL # default selection\n",
    "\n",
    "def selection_changed(event):\n",
    "    global selection\n",
    "    selection = combo.get()\n",
    "    updateModelUse(selection)\n",
    "    currentbot = getCurrentServebot(knowledge_base)\n",
    "    messagebox.showinfo(\n",
    "        title=\"New Selection\",\n",
    "        message=f\"Selected option: {selection}\"\n",
    "    )\n",
    "\n",
    "combo = ttk.Combobox(\n",
    "    state=\"readonly\",\n",
    "    values=[ MISTRAL, GPT, DIALO ]\n",
    ")\n",
    "combo.set(MISTRAL) # set default\n",
    "combo.place(x=10, y=50)\n",
    "combo.bind(\"<<ComboboxSelected>>\", selection_changed) # event\n",
    "\n",
    "# ------------------------- button ------------------------- \n",
    "micBtn = ttk.Button(mainWin, text=\"Mic\", command=lambda: listen())\n",
    "micBtn.place(x=10, y=20)\n",
    "\n",
    "export = ttk.Button(mainWin, text=\"Export Conversation\", command=lambda: exportConvo())\n",
    "export.place(x=10, y=80)\n",
    "\n",
    "mainWin.bind('<Return>',lambda event:callback())\n",
    "    \n",
    "# ------------------------- text ------------------------- \n",
    "# Create the chatbot's text area\n",
    "text_area = Text(mainWin, bg=\"white\", width=50, height=20)\n",
    "text_area.pack()\n",
    "    \n",
    "## looping start and receive input ....\n",
    "    # open the file\n",
    "knowledge_base: dict = load_knowledge_base(knowledge_path)\n",
    "    \n",
    "    # store model use into json\n",
    "# updateCurrentServebot(knowledge_path, knowledge_base)\n",
    "currentbot = getCurrentServebot(knowledge_base)\n",
    "\n",
    "mainWin.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593e5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99183ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
